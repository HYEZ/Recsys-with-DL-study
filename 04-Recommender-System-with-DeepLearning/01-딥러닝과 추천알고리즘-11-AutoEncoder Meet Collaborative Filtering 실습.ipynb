{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder Meet Collaborative Filtering\n",
    "\n",
    "- Collaborative Filtering을 위해 user-item matrix 만들기\n",
    "- AutoEncoder 모델 구조 정의하기\n",
    "\n",
    "* Training Deep AutoEncoder 논문은 [저자 코드](https://github.com/NVIDIA/DeepRecommender) 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 논문 종류\n",
    "- AutoRec\n",
    "- Training Deep AutoEncoder\n",
    "- Variational AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/kmrd/kmr_dataset/datafile/kmrd-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_df, val_df, user_to_index, movie_to_index = read_data(data_path=data_path)(data_path):\n",
    "    df = pd.read_csv(os.path.join(data_path,'rates.csv'))[:10000]\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=1234, shuffle=True)\n",
    "\n",
    "    user_to_index = {original: idx for idx, original in enumerate(df.user.unique())}\n",
    "    movie_to_index = {original: idx for idx, original in enumerate(df.movie.unique())}\n",
    "\n",
    "    return train_df, val_df, user_to_index, movie_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMRDdataset(Dataset):\n",
    "    def __init__(self, df, user_to_index, movie_to_index, item_based=True):\n",
    "        self.min_rating = min(df.rate)\n",
    "        self.max_rating = max(df.rate)\n",
    "\n",
    "        self.user = [user_to_index[u] for u in df.user.values]\n",
    "        self.movie = [movie_to_index[m] for m in df.movie.values]\n",
    "        self.rating = df.rate.values\n",
    "\n",
    "        if item_based:\n",
    "            input_tensor = torch.LongTensor([self.movie, self.user])\n",
    "            self.data = torch.sparse.FloatTensor(input_tensor, torch.FloatTensor(self.rating),\n",
    "                                             torch.Size([len(movie_to_index), len(user_to_index)])).to_dense()\n",
    "        else:\n",
    "            input_tensor = torch.LongTensor([self.user, self.movie])\n",
    "            self.data = torch.sparse.FloatTensor(input_tensor, torch.FloatTensor(self.rating),\n",
    "                                             torch.Size([len(user_to_index), len(movie_to_index)])).to_dense()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, user_to_index, movie_to_index = read_data(data_path=data_path)\n",
    "\n",
    "train_dataset = KMRDdataset(train_df, user_to_index, movie_to_index)\n",
    "val_dataset = KMRDdataset(val_df, user_to_index, movie_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 4)\n",
      "torch.Size([466])\n",
      "(2000, 4)\n",
      "torch.Size([466])\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_dataset.data[0].size())\n",
    "print(val_df.shape)\n",
    "print(val_dataset.data[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.KMRDdataset at 0x10f37b790>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466\n"
     ]
    }
   ],
   "source": [
    "print(len(list(user_to_index.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0., 27.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  8.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  8.,  9.,  0., 10.,  0.,  9.,  0.,  0.,\n",
       "         0.,  0.,  5.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  9.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  9.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0., 10.,  0.,  1.,  0.,  0.,  0., 10.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  9.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         9.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  8.,  0.,  0., 10.,  0.,  0., 10.,  0.,  0.,  0.,\n",
       "         0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  9.,  0.,  0., 10.,  0.,  0.,\n",
       "         7.,  0.,  0.,  0.,  0.,  8.,  0.,  7.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  9.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 19.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  9.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  8.,  0.,\n",
       "        10.,  0.,  0., 10., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 20.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  9.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 20.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0., 20.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(user_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(movie_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define AutoEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as weight_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAutoEncoder(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, kind='sigmoid', dropout=None):\n",
    "        super(SimpleAutoEncoder, self).__init__()\n",
    "        # encoder -> hidden -> decoder\n",
    "        # input -> hidden -> output\n",
    "        # input -> hidden : encoder\n",
    "        # hidden -> output = input : decoder\n",
    "        self.encoder = nn.Sequential(nn.Linear(num_inputs, num_hiddens), self.activation(kind))\n",
    "        self.decoder = nn.Sequential(nn.Linear(num_hiddens, num_inputs), self.activation(kind))  \n",
    "\n",
    "    def activation(self, kind):\n",
    "        if kind == 'selu':\n",
    "            return nn.SELU()\n",
    "        elif kind == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif kind == 'relu6':\n",
    "            return nn.ReLU6()\n",
    "        elif kind == 'sigmoid':\n",
    "            return nn.Sigmoid()\n",
    "        elif kind == 'tanh':\n",
    "            return nn.Tanh()\n",
    "        elif kind == 'elu':\n",
    "            return nn.ELU()\n",
    "        elif kind == 'lrelu':\n",
    "            return nn.LeakyReLU()\n",
    "        elif kind == 'none':\n",
    "            return input\n",
    "        else:\n",
    "            raise ValueError('Unknown non-linearity type')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_hiddens, num_layers, dropout=None, nn_type='diamond'):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # input -> hidden -> output\n",
    "        # input -> hidden(10) -> ... -> hidden(10) -> output = input\n",
    "        self.encoder, self.decoder = self.generate_layers(num_hiddens, num_layers, dropout, nn_type)\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "  \n",
    "    def generate_layers(self, num_hiddens, num_layers, dropout=None, nn_type='diamond'):\n",
    "        # hidden layers -> [50, 25, 12, 6, 12, 25, 50], [100 50 100] -> 100, 50, 60, 50 100 \n",
    "        if nn_type == 'diamond':\n",
    "            encoder_modules = []\n",
    "            decoder_modules = []\n",
    "\n",
    "            hidden_layers = []\n",
    "            temp = num_hiddens\n",
    "            for idx, x in enumerate(range(num_layers)):\n",
    "                if idx == 0:\n",
    "                    hidden_layers.append(temp)\n",
    "                else:\n",
    "                    hidden_layers.append(int(temp/2))\n",
    "            temp = temp/2\n",
    "            hidden_layers = [x for x in hidden_layers if x > 10]\n",
    "\n",
    "          # encoder\n",
    "            for idx, num_hidden in enumerate(hidden_layers):\n",
    "                if idx < len(hidden_layers)-1:\n",
    "                    encoder_modules.append(nn.Linear(hidden_layers[idx], hidden_layers[idx+1], bias=True))\n",
    "                    encoder_modules.append(nn.Sigmoid())\n",
    "\n",
    "          # decoder\n",
    "            hidden_layers = list(reversed(hidden_layers))\n",
    "            for idx, num_hidden in enumerate(hidden_layers):\n",
    "                if idx < len(hidden_layers)-1:\n",
    "                    decoder_modules.append(nn.Linear(hidden_layers[idx], hidden_layers[idx+1], bias=True))\n",
    "                    decoder_modules.append(nn.Identity())\n",
    "\n",
    "        # num_hidden = 50, num_layers = 3 ->  input_dim -> [50, 50, 50] -> output_dim = input_dim \n",
    "        elif nn_type == 'constant':\n",
    "            hidden_layers = [num_hiddens] * num_layers\n",
    "            for idx, enc in enumerate(hidden_layers):\n",
    "                if idx < num_layers-1:\n",
    "                    encoder_modules.append(nn.Linear(hidden_layers[idx], hidden_layers[idx+1], bias=True))\n",
    "                    encoder_modules.append(nn.Sigmoid())\n",
    "                    decoder_modules.append(nn.Linear(hidden_layers[idx], hidden_layers[idx+1], bias=True))\n",
    "                    decoder_modules.append(nn.Identity())\n",
    "\n",
    "        if dropout is not None:    \n",
    "            encoder_modules = [x for y in (encoder_modules[i:i+2] + [nn.Dropout(dropout)] * (i < len(encoder_modules) - 1) \n",
    "                              for i in range(0, len(encoder_modules), 2)) for x in y]\n",
    "            decoder_modules = [x for y in (decoder_modules[i:i+2] + [nn.Dropout(dropout)] * (i < len(decoder_modules) - 1)\n",
    "                              for i in range(0, len(decoder_modules), 2)) for x in y]\n",
    "\n",
    "        encoder = nn.Sequential(*encoder_modules)\n",
    "        decoder = nn.Sequential(*decoder_modules)\n",
    "\n",
    "        return encoder, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466 532\n"
     ]
    }
   ],
   "source": [
    "num_users = len(user_to_index.keys())\n",
    "num_movies = len(movie_to_index.keys())\n",
    "print(num_users, num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleAutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=466, out_features=100, bias=True)\n",
       "    (1): SELU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=466, bias=True)\n",
       "    (1): SELU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleAutoEncoder(num_inputs=num_users, num_hiddens=100, kind='selu')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleAutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=466, out_features=100, bias=True)\n",
       "    (1): SELU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=466, bias=True)\n",
       "    (1): SELU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([466])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVIDIA Recommender System 참고\n",
    "def MSEloss(inputs, targets, size_average=False):\n",
    "    mask = targets != 0\n",
    "    num_ratings = torch.sum(mask.float())\n",
    "    criterion = nn.MSELoss(reduction='sum' if not size_average else 'mean')\n",
    "    return criterion(inputs * mask.float(), targets), Variable(torch.Tensor([1.0])) if size_average else num_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.787084579467773\n",
      "11.363252639770508\n",
      "11.4984343846639\n",
      "10.804795980453491\n",
      "10.46843376159668\n",
      "10.538475036621094\n",
      "10.246515137808663\n",
      "10.680930137634277\n",
      "10.342405054304335\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_loss = 0\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred = model(batch)\n",
    "    loss, num_ratings = MSEloss(pred, batch)    \n",
    "    loss = torch.sqrt(loss / num_ratings)\n",
    "    loss.backward()\n",
    "    train_loss += loss.item() \n",
    "    optimizer.step()\n",
    "    \n",
    "    print(train_loss / (idx+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.686783790588379\n",
      "8.305405378341675\n",
      "8.46501366297404\n",
      "8.456071496009827\n",
      "8.275437927246093\n",
      "8.160489161809286\n",
      "8.385420594896589\n",
      "8.340406596660614\n",
      "8.268771436479357\n",
      "8.208452606201172\n",
      "8.209791963750666\n",
      "8.172353307406107\n",
      "8.166303964761587\n",
      "8.322408369609288\n",
      "8.31943057378133\n",
      "8.29599916934967\n",
      "8.292543355156393\n",
      "8.27474331855774\n",
      "8.267130425101833\n",
      "8.282361435890198\n",
      "8.349243913378034\n",
      "8.393507805737583\n",
      "8.378307031548541\n",
      "8.31652836004893\n",
      "8.316402015686036\n",
      "8.371596042926495\n",
      "8.395281509116844\n",
      "8.433735540934972\n",
      "8.403057114831332\n",
      "8.407469669977823\n",
      "8.400179509193666\n",
      "8.441355720162392\n",
      "8.442356181867195\n",
      "8.434548953000236\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_loss = 0\n",
    "with torch.no_grad():\n",
    "    for idx, batch in enumerate(val_dataloader):\n",
    "        pred = model(batch)\n",
    "        loss, num_ratings = MSEloss(pred, batch)\n",
    "        loss = torch.sqrt(loss / num_ratings)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        print(val_loss/(idx+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
